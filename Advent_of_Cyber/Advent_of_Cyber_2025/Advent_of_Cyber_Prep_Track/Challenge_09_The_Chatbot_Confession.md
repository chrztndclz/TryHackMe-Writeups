## The Chatbot Confession

---

## Description

TBFC’s AI assistant, FestiveBot, was meant to help write cheerful emails, but it’s been spilling secrets.
Some messages reveal internal URLs and even passwords.

AI tools can be powerful, but defenders must know how to prevent them from oversharing.

Objective:
Identify which chatbot messages contain sensitive information.

Steps:

Read each line of the conversation.

Select the ones containing private data.

Submit your findings.

---

## Analysis

This challenge highlights the risks of AI assistants oversharing sensitive information. Even automated tools can inadvertently reveal internal URLs, credentials, or confidential data, so careful review of AI outputs is critical for security.

---

## Methodology

Step 1: Read the conversation

<img width="885" height="805" alt="image" src="https://github.com/user-attachments/assets/100d29a4-f897-4b4a-a1eb-0b19087652ed" />

Step 2: Select suspicious chatbot replies

The ones containing private data

<img width="864" height="839" alt="image" src="https://github.com/user-attachments/assets/1dd30b91-fe69-4678-84e1-3fd7fa06b39f" />

Step 3: Submit and retrieve the flag 

<img width="899" height="419" alt="image" src="https://github.com/user-attachments/assets/4d1aa99d-f3ab-488e-af8b-fc3199981015" />

---

## Flag

THM{Don------------Bot}

---

## Reflection 

This exercise demonstrates the need for monitoring AI outputs and controlling access to sensitive data. Proper governance prevents accidental leaks, even from helpful tools.

---

## Tools

(none)
